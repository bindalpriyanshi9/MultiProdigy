MultiProdigy - LLM Plugin Registry System
This project implements a pluggable LLM client interface and registry system, enabling flexible integration and testing of different LLM backends.

ðŸ“ Project Structure
bash
Copy
Edit
multi_prodigy/
â”‚
â”œâ”€â”€ base.py           # Abstract base class defining LLMClient interface
â”œâ”€â”€ factory.py        # Registry for registering and retrieving LLM clients
â”œâ”€â”€ dummy.py          # Dummy LLM implementation
â”œâ”€â”€ test_dummy.py     # Simple test to verify DummyLLM integration
â””â”€â”€ README.md         # Project documentation
ðŸ“Œ Purpose
This system allows:

Defining a standard interface for LLMs

Registering different implementations using unique names

Instantiating registered LLMs at runtime

Easily mocking or testing components with dummy clients

ðŸ§© Components
LLMClient (base.py)
An abstract base class for any LLM client.

python
Copy
Edit
class LLMClient(ABC):
    @abstractmethod
    def generate(self, prompt: str, **kwargs) -> str: pass

    @abstractmethod
    def embed(self, texts: List[str], **kwargs) -> List[List[float]]: pass

    @abstractmethod
    def chat(self, messages: List[dict], **kwargs) -> str: pass
register_llm, get_llm, list_registered_llms (factory.py)
Functions to manage the LLM registry:

register_llm(name, client_cls) â€“ Register a client class with a name

get_llm(name, **kwargs) â€“ Retrieve and instantiate a client

list_registered_llms() â€“ View all registered LLMs

Example:

python
Copy
Edit
register_llm("openai", OpenAIClient)
client = get_llm("openai", api_key="xyz")
DummyLLM (dummy.py)
A simple mock implementation of LLMClient, useful for testing.

python
Copy
Edit
class DummyLLM(LLMClient):
    def generate(self, prompt: str) -> str:
        return f"Echo: {prompt}"
    def embed(self, texts: List[str]) -> List[List[float]]:
        return [[0.1]*5 for _ in texts]
    def chat(self, messages: List[dict]) -> str:
        return "Hello from DummyLLM"
âœ… Testing
A quick test is included to validate registration and method calls:

python
Copy
Edit
register_llm("dummy", DummyLLM)
client = get_llm("dummy")

assert client.generate("Test") == "Echo: Test"
assert client.embed(["a", "b"]) == [[0.1]*5, [0.1]*5]
assert client.chat([]) == "Hello from DummyLLM"

print("All tests passed!")
ðŸš€ Usage
Clone the repo and run:

bash
Copy
Edit
python test_dummy.py
You'll see:

css
Copy
Edit
All tests passed!
ðŸ“Œ Future Scope
Add real implementations (e.g., OpenAI, Cohere, Claude)

Expand chat() method to maintain memory/state

Plug into your chatbot or RAG pipelines

ðŸ§  License
This project is open-source and available under the MIT License.
